name: Deploy Preprocess Power Level Lambda

on:
  # Trigger the workflow on push
  push:
    branches: [ "main", "development" ] # push events on main branch
    # paths:
    #   - "preprocess-power-level/**" # TODO: UNCOMMENT WHEN YML FILE IS READY
    #   - "services/**"
    #   - "libs/**"
    #   - "requirements.txt"

env:
  PYTHON_VERSION: "3.12"
  BASE_FOLDER_NAME: "preprocess_power_level"
  S3_BUCKET_NAME: "rift-rewind-chrisbryann"
  LAMBDA_FUNCTION_NAME: "preprocess-power-level"

# the job defines a series of steps that execute on the same runner
jobs:
  CI:
    # Define the runner used in the workflow
    runs-on: ubuntu-22.04
    steps:
      # Check out repo so our workflow can access it
      - uses: actions/checkout@v4

      # Step-1 Setup Python
      - name: Set up Python
        # This action sets up a Python environment for use in actions
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          # optional: architecture: x64 x64 or x86. Defaults to x64 if specified

      # Step-2 Install Python Virtual ENV
      - name: Install Python Virtual ENV
        run: pip3 install virtualenv

      # Step-3 Setup Virtual ENV
      # cache dependencies
      - name: Virtual ENV
        uses: actions/cache@v4
        id: cache-venv # name for referring later
        with:
          path: venv # what we cache: the virtual env
          # The cache key depends on requirements.txt
          key: ${{ runner.os }}-venv-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-venv-

      # Step-4 Build a Virtual ENV, but only if it doesn't already exists
      - name: Activate Virtual ENV
        run: python -m venv venv && source venv/bin/activate && pip3 install -r requirements.txt
        if: steps.cache-venv.outputs.cache-hit != 'true'
      
      # - name: Run Tests
      #   # Note that you have to activate the virtualenv in every step
      #   # because Github actions doesn't preserve the environment
      #   run: . venv/bin/activate && pytest
      
      - name: Create archive of dependencies
        run: |
          cd ./venv/lib/python${{ env.PYTHON_VERSION }}/site-packages
          zip -r9 ../../../../${{ env.BASE_FOLDER_NAME }}.zip .
      
      - name: Add ${{ env.BASE_FOLDER_NAME }} files to Zip file
        run: zip -r ${{ env.BASE_FOLDER_NAME }}.zip ${{ env.BASE_FOLDER_NAME }} -x '**/__pycache__/*' '*.pyc'
      
      - name: Add /services files to Zip file
        run: zip -r ${{ env.BASE_FOLDER_NAME }}.zip services -x '**/__pycache__/*' '*.pyc'

      - name: Add /libs files to Zip file
        run: |
          if [ -d libs ]; then
            zip -r ${{ env.BASE_FOLDER_NAME }}.zip libs -x '**/__pycache__/*' '*.pyc'
          fi

      - name: Upload zip file artifact
        # uploads artifacts from your workflow allowing you to share data between jobs
        # Stores data once a workflow is complete
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_FOLDER_NAME }}
          path: ${{ env.BASE_FOLDER_NAME }}.zip
  CD:
    runs-on: ubuntu-latest
    needs: [CI]
    # if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - name: Install AWS CLI
        uses: unfor19/install-aws-cli-action@v1
        with:
          version: 1
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY_SECRET }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
  
      - name: Download Lambda ${{ env.BASE_FOLDER_NAME }}.zip
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.BASE_FOLDER_NAME }}
  
      - name: Upload to S3
        run: aws s3 cp ${{ env.BASE_FOLDER_NAME }}.zip s3://${{ env.S3_BUCKET_NAME }}/${{ env.BASE_FOLDER_NAME }}.zip
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY_SECRET }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
  
      - name: Deploy new Lambda and wait until finish deployment
        run: |
          aws lambda update-function-code \
          --function-name ${{ env.LAMBDA_FUNCTION_NAME }} \
          --s3-bucket ${{ env.S3_BUCKET_NAME }} \
          --s3-key ${{ env.BASE_FOLDER_NAME }}.zip

          # Wait until the function is out of "InProgress"
          aws lambda wait function-updated \
            --function-name ${{ env.LAMBDA_FUNCTION_NAME }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY_SECRET }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

      - name: Update AWS Lambda environment variables
        run: |
          aws lambda update-function-configuration \
            --function-name ${{ env.LAMBDA_FUNCTION_NAME }} \
            --environment "Variables={DB_ARN=${{ secrets.DB_ARN }},SECRET_ARN=${{ secrets.DB_SECRET_ARN }},DB_NAME=${{ secrets.DB_NAME }},RIOT_API_KEY=${{ secrets.RIOT_API_KEY }},ENV=${{ secrets.ENV }}}"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY_SECRET }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}